{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment # 5\n"
      ],
      "metadata": {
        "id": "JS997cfZaJsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Automated File Management and Data Export System\n"
      ],
      "metadata": {
        "id": "Q0kL0lZqaPwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mngItTbeaVZo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"csv_files\", exist_ok=True)\n",
        "os.makedirs(\"backup_folder\", exist_ok=True)"
      ],
      "metadata": {
        "id": "-c0G6Pwvae8X"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "df_Wnbiya5Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = pd.DataFrame({\n",
        "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
        "    \"Age\": [25, 30, 35],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"]\n",
        "})\n",
        "\n",
        "for i in range(1, 4):\n",
        "    sample_data.to_csv(f\"csv_files/sample_{i}.csv\", index=False)"
      ],
      "metadata": {
        "id": "0y0yQmZ9alWw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = glob.glob(\"csv_files/*.csv\")\n",
        "\n",
        "for file in csv_files:\n",
        "    shutil.move(file, \"backup_folder/\")\n",
        "    print(f\"Moved file: {file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EAH12jSatHO",
        "outputId": "4951f127-e145-4afd-a191-5411d9c46dd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved file: csv_files/sample_1.csv\n",
            "Moved file: csv_files/sample_2.csv\n",
            "Moved file: csv_files/sample_3.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbIxwFtvaFHS",
        "outputId": "377b8633-07e3-40c9-816f-f64f8839f8c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data exported to output.csv in CSV format.\n",
            "Data exported to output.json in JSON format.\n"
          ]
        }
      ],
      "source": [
        "def export_data(df, filename, format):\n",
        "    if format == \"csv\":\n",
        "        df.to_csv(filename, index=False)\n",
        "        print(f\"Data exported to {filename} in CSV format.\")\n",
        "    elif format == \"json\":\n",
        "        df.to_json(filename, orient=\"records\")\n",
        "        print(f\"Data exported to {filename} in JSON format.\")\n",
        "    else:\n",
        "        print(\"Unsupported format.\")\n",
        "\n",
        "df = pd.DataFrame(sample_data)\n",
        "\n",
        "export_data(df, \"output.csv\", \"csv\")\n",
        "export_data(df, \"output.json\", \"json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Real-Time Stock Market Data Collection and Analysis"
      ],
      "metadata": {
        "id": "4UqD0yx8a09U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "-Zqk5mgvaQqx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_name = \"stocks.db\"\n",
        "conn = sqlite3.connect(db_name)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute('''CREATE TABLE IF NOT EXISTS stock_data (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                symbol TEXT,\n",
        "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                open REAL,\n",
        "                high REAL,\n",
        "                low REAL,\n",
        "                close REAL,\n",
        "                volume INTEGER)''')\n",
        "conn.commit()"
      ],
      "metadata": {
        "id": "TDPZWeZkbJwT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_stock_data(symbol):\n",
        "    try:\n",
        "        stock = yf.Ticker(symbol)\n",
        "        data = stock.history(period=\"1d\", interval=\"1m\")\n",
        "\n",
        "        if data.empty:\n",
        "            print(f\"No data found for {symbol}. Skipping...\")\n",
        "            return None\n",
        "\n",
        "        latest = data.iloc[-1]\n",
        "        return {\n",
        "            \"symbol\": symbol,\n",
        "            \"open\": latest[\"Open\"],\n",
        "            \"high\": latest[\"High\"],\n",
        "            \"low\": latest[\"Low\"],\n",
        "            \"close\": latest[\"Close\"],\n",
        "            \"volume\": latest[\"Volume\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data for {symbol}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Nufa0ccGbOI1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_data(symbol):\n",
        "    stock_data = fetch_stock_data(symbol)\n",
        "    if stock_data:\n",
        "        cursor.execute('''INSERT INTO stock_data (symbol, open, high, low, close, volume)\n",
        "                          VALUES (?, ?, ?, ?, ?, ?)''',\n",
        "                       (stock_data[\"symbol\"], stock_data[\"open\"],\n",
        "                        stock_data[\"high\"], stock_data[\"low\"],\n",
        "                        stock_data[\"close\"], stock_data[\"volume\"]))\n",
        "        conn.commit()\n",
        "        print(f\"Stored data for {symbol}\")"
      ],
      "metadata": {
        "id": "AZEpA9qwbRdy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_stock(symbol):\n",
        "    df = pd.read_sql_query(\"SELECT * FROM stock_data WHERE symbol=? ORDER BY timestamp DESC LIMIT 100\", conn, params=(symbol,))\n",
        "    print(df)\n",
        ""
      ],
      "metadata": {
        "id": "V83ieCcvbUWJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symbol = input(\"Enter which stock you want to analyze\").upper()\n",
        "for _ in range(5):\n",
        "    store_data(symbol)\n",
        "    time.sleep(60)  # Wait for 1 minute before fetching again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nBEcqHfbaoC",
        "outputId": "6770a82b-0570-4f58-b6d5-911a4dccaabc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter which stock you want to analyzenvda\n",
            "Stored data for NVDA\n",
            "Stored data for NVDA\n",
            "Stored data for NVDA\n",
            "Stored data for NVDA\n",
            "Stored data for NVDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_stock(symbol)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvPdt77Bcr6W",
        "outputId": "937333eb-8dd7-4460-d076-fd04a6c8021b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id symbol            timestamp        open        high         low  \\\n",
            "0  19   NVDA  2025-02-18 14:39:55  142.229706  142.229706  142.229706   \n",
            "1  18   NVDA  2025-02-18 14:38:55  142.419998  142.419998  142.419998   \n",
            "2  17   NVDA  2025-02-18 14:37:55  142.514999  142.514999  142.514999   \n",
            "3  16   NVDA  2025-02-18 14:36:54  142.859894  142.859894  142.859894   \n",
            "4  15   NVDA  2025-02-18 14:35:54  143.399994  143.399994  143.399994   \n",
            "\n",
            "        close  volume  \n",
            "0  142.229706       0  \n",
            "1  142.419998       0  \n",
            "2  142.514999       0  \n",
            "3  142.859894       0  \n",
            "4  143.399994       0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conn.close()"
      ],
      "metadata": {
        "id": "xLakLfr7box3"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Augmented Reality Transformation â€“ Perform linear algebra operations like scaling, rotation, and translation"
      ],
      "metadata": {
        "id": "4ZkfmA4bdEGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "csZ_EhPKdM1o"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://books.toscrape.com/\"\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}"
      ],
      "metadata": {
        "id": "6DCB-i5jdVXa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_books(url):\n",
        "    response = requests.get(url, headers=HEADERS)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
        "    book_list = []\n",
        "\n",
        "    for book in books:\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text\n",
        "        stock = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "\n",
        "        book_list.append({\"Title\": title, \"Price\": price, \"Availability\": stock})\n",
        "\n",
        "    return book_list"
      ],
      "metadata": {
        "id": "_6I-HCbPdX16"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_data = get_books(URL)"
      ],
      "metadata": {
        "id": "dDGQ9nRAdaAc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(books_data)\n",
        "df.to_csv(\"books.csv\", index=False)\n",
        "print(\"Data saved to books.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5dhL1T_dcA6",
        "outputId": "a9cd9b5f-1f54-49c0-db74-3134063137f0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to books.csv\n"
          ]
        }
      ]
    }
  ]
}